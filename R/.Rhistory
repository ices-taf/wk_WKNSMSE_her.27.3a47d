install.packages("devtools")
install.packages("dplyr")
library(devtools)
capabilities("tcltk")
library(devtools)
install.packages("devtools")
install.packages("processx ")
install.packages("processx")
install.packages("devtools")
install.packages("processx")
install.packages("devtools")
install_github(repo="flr/FLSAM",ref="develop_V2"
)
find.package("devtools")
library(devtools)
install_github(repo="flr/FLSAM",ref="develop_V2")
install_github(repo="flr/FLSAM",ref="develop_V2")
install_github(repo="flr/FLSAM",ref="develop_V2")
remove.packages("TMB")
find.package(TMB)
find.package("TMB")
library(TMB)
.libPaths()
.libPaths("C:/Program Files/R/R-3.4.3/library")
install.packages("stockassessment")
install.packages("stockassessment")
install_github(repo="flr/FLSAM",ref="develop_V2")
.libPaths
.libPaths()
library(devtools)
install_github(repo="flr/FLSAM",ref="develop_V2")
.libPaths()
.libPaths("C:/Program Files/R/R-3.5.1/library")
library(devtools)
install_github(repo="flr/FLSAM",ref="develop_V2")
remove.packages(Rcpp)
remove.packages("Rcpp")
install_github(repo="flr/FLSAM",ref="develop_V2")
install.packages("Rtools")
.libPaths()
.libPaths("C:/Program Files/R/R-3.4.4/library")
install.packages("devtools")
install_github(repo="flr/FLSAM",ref="develop_V2")
library(devtools)
install_github(repo="flr/FLSAM",ref="develop_V2")
.libPaths()
.libPaths("C:/Program Files/R/R-3.5.1/library")
install.packages("knitr")
.libPaths()
.libPaths("C:/Program Files/R/R-3.5.1/library")
install.packages("knitr")
.libPaths()
.libPaths("C:/Program Files/R/R-3.5.1/library")
data(ple4)
library(FLCore)
data(ple4)
flc <- as(ple4, "FLCatch")
?FLStock
#-------------------------------------------------------------------------------
# WKNSMSE
#
# Author: Benoit Berges
#         WMR, The Netherland
# email: benoit.berges@wur.nl
#
#  MSE of North Sea Herring
#
# Date: 2018/11/18
#
# Build for R3.5.1, 64bits
#-------------------------------------------------------------------------------
#-------------------------------------------------------------------------------
# 1) load packages
#    setup paths
#    load functions
#-------------------------------------------------------------------------------
rm(list=ls())
library(FLSAM)
library(FLEDA)
# define path to directory
#path          <- "D:/Work/Herring MSE/NSAS/"
path              <- "D:/git/wk_WKNSMSE_her.27.3a47d/R/"
#path              <- "F:/WKNSMSE/wk_WKNSMSE_her.27.3a47d/R"
assessment_name   <- "NSAS_WKNSMSE2018"
try(setwd(path),silent=TRUE)
# paths to different subfolders
dataPath      <- file.path(".","data/")
outPath       <- file.path(".","results/")
scriptPath    <- file.path(".","side_scripts/")
functionPath  <- file.path(".","functions/")
# loading function
source(file.path(functionPath,"randBlocks.R"))
source(file.path(functionPath,"randNums.R"))
#-------------------------------------------------------------------------------
# 2) load assessment objects (single and multi fleet)
#    define MSE parameters
#    load raw M
#
# Note 1: the assessments we use is without the LAI index. The assessments that
# are ran during HAWG is using the LAI so results are slightly different. See
# 00_test_no_LAI.R for a comparison of the assessments. This is for convenience
# as the LAI is a component index and is weekly structured, therefore
# complicated to implement
#-------------------------------------------------------------------------------
#- Load single fleet and multi fleet assessment objects - using assessments without the LAI
#load(file.path(outPath,paste0(assessment_name,'_mf.Rdata')))
#load(file.path(outPath,paste0(assessment_name,'_sf.Rdata')))
load(file.path(outPath,paste0(assessment_name,'_mf_noLAI.Rdata')))
load(file.path(outPath,paste0(assessment_name,'_sf_noLAI.Rdata')))
# parameters
n.retro.years       <-  7                                       # Number of years for which to run the retrospective
nFutureyrs          <- 20
histMinYr           <- dims(NSH)$minyear
histMaxYr           <- dims(NSH)$maxyear
yearCurrent         <- histMinYr:histMaxYr # vector the years
futureMaxYr         <- histMaxYr + nFutureyrs
histPeriod          <- ac(histMinYr:histMaxYr)
projPeriod          <- ac((histMaxYr+1):futureMaxYr)
fullPeriod          <- c(histPeriod,projPeriod)
recrPeriod          <- ac(2007:2017)
selPeriod           <- ac(2007:2017)
fecYears            <- ac(2007:2017)
nits                <- 10 # number of random samples
# reading the raw M and applying plus group
raw_M             <- read.csv(file.path(dataPath,"Smoothed_span50_M_NotExtrapolated_NSASSMS2016.csv"),header=TRUE)
colnames(raw_M)   <- sub("X","",colnames(raw_M))
rownames(raw_M)   <- raw_M[,1]
raw_M             <- raw_M[,-1]# Trim off first column as it contains 'ages'
raw_M             <- cbind(replicate(as.numeric(colnames(raw_M)[1])-histMinYr,raw_M[,1]), raw_M)
raw_M             <- cbind(raw_M,raw_M[,dim(raw_M)[2]])
colnames(raw_M)   <- histMinYr:histMaxYr
# hack to set plus group, converting M array into an FLStock object, using the setPlusGroup, then back to array
# !!!!!! to be updated. Right now one uses an empty FLStock object. This is wrong as I think the setting of the plus group
# needs the catches as input
NSHM2             <- readFLStock(file.path(dataPath,"index.txt"),no.discards=TRUE,quiet=FALSE)
NSHM2@m[]         <- as.matrix(raw_M)
pg                <- NSH@range['max']
NSHM2             <- setPlusGroup(NSHM2,pg) # really wonder if the setPlusGroup does anything... Needs clarifying.
raw_M             <- drop(NSHM2@m)
raw_M             <- raw_M + 0.11
#-------------------------------------------------------------------------------
# 3) create random samples using variance/covariance matrix
#-------------------------------------------------------------------------------
NSH.sim         <- simulate(NSH,NSH.tun,NSH.ctrl,n=nits)
names(NSH.sim)  <- paste0('iter',1:nits)
#-------------------------------------------------------------------------------
# 4) create FLStocks object using random samples (with future years as NA)
#-------------------------------------------------------------------------------
stocks          <- NSH + NSH.sim # from FLSAMs to FLStocks
stocks          <- window(window(stocks,end=histMaxYr+1),start=histMinYr,end=futureMaxYr) # extend the FLStock object to the full projection period
# update FLStocks object with random samples infered from variance/co-variance matrix
for(idxIter in 1:nits){
stocks[[idxIter]]@catch.n                    <- stocks[[idxIter]]@stock.n * stocks[[idxIter]]@harvest /
(stocks[[idxIter]]@harvest + stocks[[idxIter]]@m) *
(1 - exp(-stocks[[idxIter]]@harvest - stocks[[idxIter]]@m)) # compute catch numbers
stocks[[idxIter]]@catch.n[,ac(1978:1979)]    <- NA # fill in Na for the the closure catch data
stocks[[idxIter]]@landings.n                 <- stocks[[idxIter]]@catch.n
stocks[[idxIter]]@harvest.spwn[,projPeriod]  <- stocks[[idxIter]]@harvest.spwn[,ac(histMaxYr)] # propagate Fprop before spawning
stocks[[idxIter]]@m.spwn[,projPeriod]        <- stocks[[idxIter]]@m.spwn[,ac(histMaxYr)] # propagate Mprop before spawning
}
#-------------------------------------------------------------------------------
# 5) allocating future maturity, stock weight and M at age
#
# w@a and mat are on the same randomization
# M gets an independent randomization
# we randomize the following:
# number of years in the chain
# start year in the chain
# reversing of the chain
#
# Note: M is from raw_M, not the M (smoothed) from the assessment
#-------------------------------------------------------------------------------
# generate random blocks for weight at age and maturity
yrChain   <- randBlocks(an(fecYears),an(projPeriod),nits)
yrChainM  <- randBlocks(an(fecYears),an(projPeriod),nits)
# catch weight
multiFleet_catch.wt         <- array( 0, # initialize array, nAges x nYears x nFleets x nits. 3 fleets in assessment (A,BD,C)
dim=c(dim(NSHs3$residual@catch.wt)[1], # nAges
length(projPeriod),              # nYears
3,                               # nFleets
nits),                           # nits.
dimnames = list(0:(dim(NSHs3$residual@catch.wt)[1]-1),
as.numeric(projPeriod),
1:3,
1:nits))
# update FLStocks object
for(idxIter in 1:nits){
# future maturity at age
stocks[[idxIter]]@mat      [,projPeriod][]               <- array(stocks[[idxIter]]@mat[,ac(yrChain[[idxIter]])],
dim=dim(stocks[[idxIter]]@mat[,projPeriod]))
# future weight at age
stocks[[idxIter]]@stock.wt [,projPeriod][]               <- array(stocks[[idxIter]]@stock.wt[,ac(yrChain[[idxIter]])],
dim=dim(stocks[[idxIter]]@stock.wt[,projPeriod]))
# future natural mortality at age
stocks[[idxIter]]@m        [,projPeriod][]               <- array(raw_M[,ac(yrChainM[[idxIter]])],
dim=dim(stocks[[idxIter]]@m[,projPeriod]))
# multi fleet catch weight at age
multiFleet_catch.wt[,projPeriod,,idxIter] <- drop(NSHs3$residual@catch.wt[,ac(yrChain[[idxIter]])])[,1:length(projPeriod),]
}
.libPaths
.libPaths()
.libPaths("C:/Program Files/R/R-3.5.1/library")
#-------------------------------------------------------------------------------
# WKNSMSE
#
# Author: Benoit Berges
#         WMR, The Netherland
# email: benoit.berges@wur.nl
#
#  MSE of North Sea Herring
#
# Date: 2018/11/18
#
# Build for R3.5.1, 64bits
#-------------------------------------------------------------------------------
#-------------------------------------------------------------------------------
# 1) load packages
#    setup paths
#    load functions
#-------------------------------------------------------------------------------
rm(list=ls())
library(FLSAM)
library(FLEDA)
# define path to directory
#path          <- "D:/Work/Herring MSE/NSAS/"
path              <- "D:/git/wk_WKNSMSE_her.27.3a47d/R/"
#path              <- "F:/WKNSMSE/wk_WKNSMSE_her.27.3a47d/R"
assessment_name   <- "NSAS_WKNSMSE2018"
try(setwd(path),silent=TRUE)
# paths to different subfolders
dataPath      <- file.path(".","data/")
outPath       <- file.path(".","results/")
scriptPath    <- file.path(".","side_scripts/")
functionPath  <- file.path(".","functions/")
# loading function
source(file.path(functionPath,"randBlocks.R"))
source(file.path(functionPath,"randNums.R"))
#-------------------------------------------------------------------------------
# 2) load assessment objects (single and multi fleet)
#    define MSE parameters
#    load raw M
#
# Note 1: the assessments we use is without the LAI index. The assessments that
# are ran during HAWG is using the LAI so results are slightly different. See
# 00_test_no_LAI.R for a comparison of the assessments. This is for convenience
# as the LAI is a component index and is weekly structured, therefore
# complicated to implement
#-------------------------------------------------------------------------------
#- Load single fleet and multi fleet assessment objects - using assessments without the LAI
#load(file.path(outPath,paste0(assessment_name,'_mf.Rdata')))
#load(file.path(outPath,paste0(assessment_name,'_sf.Rdata')))
load(file.path(outPath,paste0(assessment_name,'_mf_noLAI.Rdata')))
load(file.path(outPath,paste0(assessment_name,'_sf_noLAI.Rdata')))
# parameters
n.retro.years       <-  7                                       # Number of years for which to run the retrospective
nFutureyrs          <- 20
histMinYr           <- dims(NSH)$minyear
histMaxYr           <- dims(NSH)$maxyear
yearCurrent         <- histMinYr:histMaxYr # vector the years
futureMaxYr         <- histMaxYr + nFutureyrs
histPeriod          <- ac(histMinYr:histMaxYr)
projPeriod          <- ac((histMaxYr+1):futureMaxYr)
fullPeriod          <- c(histPeriod,projPeriod)
recrPeriod          <- ac(2007:2017)
selPeriod           <- ac(2007:2017)
fecYears            <- ac(2007:2017)
nits                <- 10 # number of random samples
# reading the raw M and applying plus group
raw_M             <- read.csv(file.path(dataPath,"Smoothed_span50_M_NotExtrapolated_NSASSMS2016.csv"),header=TRUE)
colnames(raw_M)   <- sub("X","",colnames(raw_M))
rownames(raw_M)   <- raw_M[,1]
raw_M             <- raw_M[,-1]# Trim off first column as it contains 'ages'
raw_M             <- cbind(replicate(as.numeric(colnames(raw_M)[1])-histMinYr,raw_M[,1]), raw_M)
raw_M             <- cbind(raw_M,raw_M[,dim(raw_M)[2]])
colnames(raw_M)   <- histMinYr:histMaxYr
# hack to set plus group, converting M array into an FLStock object, using the setPlusGroup, then back to array
# !!!!!! to be updated. Right now one uses an empty FLStock object. This is wrong as I think the setting of the plus group
# needs the catches as input
NSHM2             <- readFLStock(file.path(dataPath,"index.txt"),no.discards=TRUE,quiet=FALSE)
NSHM2@m[]         <- as.matrix(raw_M)
pg                <- NSH@range['max']
NSHM2             <- setPlusGroup(NSHM2,pg) # really wonder if the setPlusGroup does anything... Needs clarifying.
raw_M             <- drop(NSHM2@m)
raw_M             <- raw_M + 0.11
#-------------------------------------------------------------------------------
# 3) create random samples using variance/covariance matrix
#-------------------------------------------------------------------------------
NSH.sim         <- simulate(NSH,NSH.tun,NSH.ctrl,n=nits)
names(NSH.sim)  <- paste0('iter',1:nits)
#-------------------------------------------------------------------------------
# 4) create FLStocks object using random samples (with future years as NA)
#-------------------------------------------------------------------------------
stocks          <- NSH + NSH.sim # from FLSAMs to FLStocks
stocks          <- window(window(stocks,end=histMaxYr+1),start=histMinYr,end=futureMaxYr) # extend the FLStock object to the full projection period
# update FLStocks object with random samples infered from variance/co-variance matrix
for(idxIter in 1:nits){
stocks[[idxIter]]@catch.n                    <- stocks[[idxIter]]@stock.n * stocks[[idxIter]]@harvest /
(stocks[[idxIter]]@harvest + stocks[[idxIter]]@m) *
(1 - exp(-stocks[[idxIter]]@harvest - stocks[[idxIter]]@m)) # compute catch numbers
stocks[[idxIter]]@catch.n[,ac(1978:1979)]    <- NA # fill in Na for the the closure catch data
stocks[[idxIter]]@landings.n                 <- stocks[[idxIter]]@catch.n
stocks[[idxIter]]@harvest.spwn[,projPeriod]  <- stocks[[idxIter]]@harvest.spwn[,ac(histMaxYr)] # propagate Fprop before spawning
stocks[[idxIter]]@m.spwn[,projPeriod]        <- stocks[[idxIter]]@m.spwn[,ac(histMaxYr)] # propagate Mprop before spawning
}
#-------------------------------------------------------------------------------
# 5) allocating future maturity, stock weight and M at age
#
# w@a and mat are on the same randomization
# M gets an independent randomization
# we randomize the following:
# number of years in the chain
# start year in the chain
# reversing of the chain
#
# Note: M is from raw_M, not the M (smoothed) from the assessment
#-------------------------------------------------------------------------------
# generate random blocks for weight at age and maturity
yrChain   <- randBlocks(an(fecYears),an(projPeriod),nits)
yrChainM  <- randBlocks(an(fecYears),an(projPeriod),nits)
# catch weight
multiFleet_catch.wt         <- array( 0, # initialize array, nAges x nYears x nFleets x nits. 3 fleets in assessment (A,BD,C)
dim=c(dim(NSHs3$residual@catch.wt)[1], # nAges
length(projPeriod),              # nYears
3,                               # nFleets
nits),                           # nits.
dimnames = list(0:(dim(NSHs3$residual@catch.wt)[1]-1),
as.numeric(projPeriod),
1:3,
1:nits))
# update FLStocks object
for(idxIter in 1:nits){
# future maturity at age
stocks[[idxIter]]@mat      [,projPeriod][]               <- array(stocks[[idxIter]]@mat[,ac(yrChain[[idxIter]])],
dim=dim(stocks[[idxIter]]@mat[,projPeriod]))
# future weight at age
stocks[[idxIter]]@stock.wt [,projPeriod][]               <- array(stocks[[idxIter]]@stock.wt[,ac(yrChain[[idxIter]])],
dim=dim(stocks[[idxIter]]@stock.wt[,projPeriod]))
# future natural mortality at age
stocks[[idxIter]]@m        [,projPeriod][]               <- array(raw_M[,ac(yrChainM[[idxIter]])],
dim=dim(stocks[[idxIter]]@m[,projPeriod]))
# multi fleet catch weight at age
multiFleet_catch.wt[,projPeriod,,idxIter] <- drop(NSHs3$residual@catch.wt[,ac(yrChain[[idxIter]])])[,1:length(projPeriod),]
}
#-------------------------------------------------------------------------------
# 6) creating survey indices
#
# survey indices are created for each random sample using Q, N, F and M at age
# residuals are added using a normal distribution with sigma as sd of observations
# I(a,y) = Q(a)*exp(-Z(A,y)*surveyProp)*N(a,y)*res(a,y)
# Z = M + F
#
# The following survey indices are to be generatred
# HERAS age 1 to 8
# IBTS-Q1 age 1
# IBTS0 age 0
# IBTS-Q3 age 0 to 5
#
# Note 1: the raw M is used here, as opposed to the smoothed one used in the
# assessment
# Note 2: we don't use the LAI index here, see assessment part
#-------------------------------------------------------------------------------
surveys     <- lapply(NSH.tun,propagate,iter=nits)
surveys     <- window(window(surveys,end=histMaxYr+1),start=histMinYr,end=futureMaxYr) # extend the FLStock object to the full projection period
# initialize array to store catchabilities
temp        <- catchabilities(NSH.sim[[idxIter]])
qMat        <- array(NA,
dim=c(dim(temp)[1],
2,
nits),
dimnames=list('fleet' = temp$fleet,
'var' = c('ages','value')))
# initialize array to store observation variance for surveys
temp        <- obs.var(NSH.sim[[idxIter]]) # getting observation variance from SAM object for the current iteration
temp        <- subset(temp, temp$fleet != 'catch unique') # subset observation variance
varSurvMat  <- array(NA,
dim=c(dim(temp)[1],
2,
nits),
dimnames=list('fleet' = temp$fleet,
'var' = c('ages','value')))
for(idxIter in 1:nits){
sdAll <- obs.var(NSH.sim[[idxIter]]) # getting observation variance from SAM object for the current iteration
qAll  <- catchabilities(NSH.sim[[idxIter]]) # getting catchabilities from SAM object for the current iteration
qMat[,1,idxIter]  <- qAll$age
qMat[,2,idxIter]  <- qAll$value
varSurvMat[,1,idxIter] <- subset(sdAll, sdAll$fleet != 'catch unique')$age
varSurvMat[,2,idxIter] <- subset(sdAll, sdAll$fleet != 'catch unique')$value
surveyNames <- as.character(unique(qAll$fleet)) # get all the survey names
# creating indices for surveys
# loop on all available surveys
for(idxSurvey in 1:length(surveyNames)){
sdSelect    <-  subset(sdAll, sdAll$fleet == surveyNames[idxSurvey]) # subset observation variance
qSelect     <- subset(qAll,qAll$fleet == surveyNames[idxSurvey])
# building residuals r(a,y)
# initialize residual array
maxYearSurvey     <- max(as.numeric(colnames(NSH.tun[[surveyNames[idxSurvey]]]@index)))
if(maxYearSurvey > histMaxYr)
maxYearSurvey <- histMaxYr
minYearSurvey     <- min(as.numeric(colnames(NSH.tun[[surveyNames[idxSurvey]]]@index)))
yearCurrentSurvey <- minYearSurvey:maxYearSurvey # vector the years in the survey
resi              <- array(0, dim=c(dim(sdSelect)[1],length(yearCurrentSurvey))) # initialize array nAges x nYears
colnames(resi)    <- yearCurrentSurvey
rownames(resi)    <- qSelect$age
# generate the residuals using a normal distribution - are residuals log or linear??? Probably log
for(idxResi in 1:dim(sdSelect)[1]){
resi[idxResi,]  <- rnorm(length(yearCurrentSurvey),
0,
sdSelect$value[idxResi])
}
NSelect     <- stocks[[idxIter]]@stock.n[match(as.character(sdSelect$age),rownames(stocks[[idxIter]]@stock.n)), # filter ages
match(as.character(yearCurrentSurvey),colnames(stocks[[idxIter]]@stock.n))]  # filter years
NSelect     <- drop(NSelect) # drop dimensions with 1 level
FSelect     <-  stocks[[idxIter]]@harvest[match(as.character(sdSelect$age),rownames(stocks[[idxIter]]@stock.n)), # filter ages for F
match(as.character(yearCurrentSurvey),colnames(stocks[[idxIter]]@stock.n))] # filter years for F
FSelect     <- drop(FSelect) # drop dimensions with 1 level
Z           <-  raw_M[match(as.character(sdSelect$age),rownames(raw_M)), # filter ages for M
match(as.character(yearCurrentSurvey),colnames(raw_M))]  # filter years for M
Z           <- Z + FSelect
surveyProp  <- mean(c(NSH.tun[[surveyNames[idxSurvey]]]@range[6],NSH.tun[[surveyNames[idxSurvey]]]@range[7]))
# update survey object
surveys[[surveyNames[idxSurvey]]]@index[,match(as.character(yearCurrentSurvey),colnames(surveys[[surveyNames[idxSurvey]]]@index)) # filling only the years available for the survey
,,,,idxIter] <- as.matrix(replicate(length(yearCurrentSurvey), qSelect$value)*exp(-Z*surveyProp)*NSelect*exp(resi))
surveys[[surveyNames[idxSurvey]]] <- surveys[[surveyNames[idxSurvey]]][,ac(minYearSurvey:futureMaxYr)]
}
}
.libPaths()
#-------------------------------------------------------------------------------
# WKNSMSE
#
# Author: Benoit Berges
#         WMR, The Netherland
# email: benoit.berges@wur.nl
#
#  MSE of North Sea Herring
#
# Date: 2018/11/18
#
# Build for R3.5.1, 64bits
#-------------------------------------------------------------------------------
#-------------------------------------------------------------------------------
# 1) load packages
#    setup paths
#    load functions
#-------------------------------------------------------------------------------
rm(list=ls())
library(FLSAM)
library(FLEDA)
# define path to directory
#path          <- "D:/Work/Herring MSE/NSAS/"
path              <- "D:/git/wk_WKNSMSE_her.27.3a47d/R/"
#path              <- "F:/WKNSMSE/wk_WKNSMSE_her.27.3a47d/R"
assessment_name   <- "NSAS_WKNSMSE2018"
try(setwd(path),silent=TRUE)
# paths to different subfolders
dataPath      <- file.path(".","data/")
outPath       <- file.path(".","results/")
scriptPath    <- file.path(".","side_scripts/")
functionPath  <- file.path(".","functions/")
# loading function
source(file.path(functionPath,"randBlocks.R"))
source(file.path(functionPath,"randNums.R"))
#-------------------------------------------------------------------------------
# 2) load assessment objects (single and multi fleet)
#    define MSE parameters
#    load raw M
#
# Note 1: the assessments we use is without the LAI index. The assessments that
# are ran during HAWG is using the LAI so results are slightly different. See
# 00_test_no_LAI.R for a comparison of the assessments. This is for convenience
# as the LAI is a component index and is weekly structured, therefore
# complicated to implement
#-------------------------------------------------------------------------------
#- Load single fleet and multi fleet assessment objects - using assessments without the LAI
#load(file.path(outPath,paste0(assessment_name,'_mf.Rdata')))
#load(file.path(outPath,paste0(assessment_name,'_sf.Rdata')))
load(file.path(outPath,paste0(assessment_name,'_mf_noLAI.Rdata')))
load(file.path(outPath,paste0(assessment_name,'_sf_noLAI.Rdata')))
# parameters
n.retro.years       <-  7                                       # Number of years for which to run the retrospective
nFutureyrs          <- 20
histMinYr           <- dims(NSH)$minyear
histMaxYr           <- dims(NSH)$maxyear
yearCurrent         <- histMinYr:histMaxYr # vector the years
futureMaxYr         <- histMaxYr + nFutureyrs
histPeriod          <- ac(histMinYr:histMaxYr)
projPeriod          <- ac((histMaxYr+1):futureMaxYr)
fullPeriod          <- c(histPeriod,projPeriod)
recrPeriod          <- ac(2007:2017)
selPeriod           <- ac(2007:2017)
fecYears            <- ac(2007:2017)
nits                <- 10 # number of random samples
# reading the raw M and applying plus group
raw_M             <- read.csv(file.path(dataPath,"Smoothed_span50_M_NotExtrapolated_NSASSMS2016.csv"),header=TRUE)
colnames(raw_M)   <- sub("X","",colnames(raw_M))
rownames(raw_M)   <- raw_M[,1]
raw_M             <- raw_M[,-1]# Trim off first column as it contains 'ages'
raw_M             <- cbind(replicate(as.numeric(colnames(raw_M)[1])-histMinYr,raw_M[,1]), raw_M)
raw_M             <- cbind(raw_M,raw_M[,dim(raw_M)[2]])
colnames(raw_M)   <- histMinYr:histMaxYr
# hack to set plus group, converting M array into an FLStock object, using the setPlusGroup, then back to array
# !!!!!! to be updated. Right now one uses an empty FLStock object. This is wrong as I think the setting of the plus group
# needs the catches as input
NSHM2             <- readFLStock(file.path(dataPath,"index.txt"),no.discards=TRUE,quiet=FALSE)
NSHM2@m[]         <- as.matrix(raw_M)
pg                <- NSH@range['max']
NSHM2             <- setPlusGroup(NSHM2,pg) # really wonder if the setPlusGroup does anything... Needs clarifying.
raw_M             <- drop(NSHM2@m)
raw_M             <- raw_M + 0.11
#-------------------------------------------------------------------------------
# 3) create random samples using variance/covariance matrix
#-------------------------------------------------------------------------------
NSH.sim         <- simulate(NSH,NSH.tun,NSH.ctrl,n=nits)
